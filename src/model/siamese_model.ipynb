{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import glob\n",
    "import cv2\n",
    "from tensorflow.keras.utils import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@3114.400] global persistence.cpp:512 open Can't open file: 'haarcascade_frontalface_default.xml' in read mode\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /Users/runner/work/opencv-python/opencv-python/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/emily/Desktop/CDS Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#print(image.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# need to bounding box here\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m image \u001b[39m=\u001b[39m draw_bounding_boxes(image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(image, (img_rows, img_cols))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m image \u001b[39m=\u001b[39m img_to_array(image)\n",
      "File \u001b[0;32m~/Desktop/CDS Work/edge-ml-pm/edge-ml/src/model/util/image_bb.py:9\u001b[0m, in \u001b[0;36mdraw_bounding_boxes\u001b[0;34m(np_img)\u001b[0m\n\u001b[1;32m      7\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(np_img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m      8\u001b[0m haar_cascade \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(\u001b[39m\"\u001b[39m\u001b[39mhaarcascade_frontalface_default.xml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m faces_rect \u001b[39m=\u001b[39m haar_cascade\u001b[39m.\u001b[39;49mdetectMultiScale(img, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m1.1\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m image_idx, (x, y, w, h) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(faces_rect):\n\u001b[1;32m     12\u001b[0m     cv2\u001b[39m.\u001b[39mrectangle(img, (x, y), (x \u001b[39m+\u001b[39m w, y \u001b[39m+\u001b[39m h), (\u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /Users/runner/work/opencv-python/opencv-python/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "# pull images from david/ folder\n",
    "images_dataset = []\n",
    "labels_dataset = []\n",
    "images_test_dataset = []\n",
    "labels_test_dataset = []\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "for image_path in glob.glob(\"train/*.jpg\"):\n",
    "    image = cv2.imread(image_path)\n",
    "    #print(image.shape)\n",
    "    # need to bounding box here\n",
    "    image = cv2.resize(image, (img_rows, img_cols))\n",
    "    image = img_to_array(image)\n",
    "    images_dataset.append(image)\n",
    "    label = image_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "    labels_dataset.append(label)\n",
    "\n",
    "for image_path in glob.glob(\"test/*.jpg\"):\n",
    "    image = cv2.imread(image_path)\n",
    "    print(image.shape, image_path)\n",
    "    # need to bounding box here\n",
    "    image = cv2.resize(image, (img_rows, img_cols))\n",
    "    image = img_to_array(image)\n",
    "    images_test_dataset.append(image)\n",
    "    label = \"david\" if \"test_david\" in image_path else \"other\"\n",
    "    labels_test_dataset.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in images_dataset, apply bounding box\n",
    "for image in images_dataset:\n",
    "    pass\n",
    "    # apply bounding box\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input((img_rows, img_cols, 3))\n",
    "    x = Conv2D(96, (11, 11), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    pooledOutput = Dense(1024)(pooledOutput)\n",
    "    outputs = Dense(128)(pooledOutput)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "feature_extractor = create_model()\n",
    "imgA = Input(shape=(img_rows, img_cols, 3))\n",
    "imgB = Input(shape=(img_rows, img_cols, 3))\n",
    "featA = feature_extractor(imgA)\n",
    "featB = feature_extractor(imgB)\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    (featA, featB) = vectors\n",
    "    sum_squared = K.sum(K.square(featA - featB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "distance = Lambda(euclidean_distance)([featA, featB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_train_image_pairs(images_dataset, labels_dataset):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    print \n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label,\n",
    "                                      [index for index, curr_label in enumerate(labels_dataset) if\n",
    "                                       label == curr_label])\n",
    "    \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for index, image in enumerate(images_dataset):\n",
    "        pos_indices = label_wise_indices.get(labels_dataset[index])\n",
    "        pos_image = images_dataset[np.random.choice(pos_indices)]\n",
    "        pair_images.append((image, pos_image))\n",
    "        pair_labels.append(1)\n",
    "\n",
    "        neg_indices = np.where(labels_dataset != labels_dataset[index])\n",
    "        neg_image = images_dataset[np.random.choice(neg_indices[0])]\n",
    "        pair_images.append((image, neg_image))\n",
    "        pair_labels.append(0)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 53s 7s/step - loss: 2.0108 - accuracy: 0.5000 - val_loss: 0.5892 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 46s 7s/step - loss: 0.7258 - accuracy: 0.5000 - val_loss: 0.6303 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 46s 7s/step - loss: 0.6947 - accuracy: 0.5000 - val_loss: 0.6730 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.6854 - accuracy: 0.5000 - val_loss: 0.6861 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 45s 6s/step - loss: 0.6663 - accuracy: 0.5000 - val_loss: 0.5773 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "## Model training\n",
    "\n",
    "images_pair, labels_pair = generate_train_image_pairs(images_dataset, labels_dataset)\n",
    "history = model.fit([images_pair[:, 0], images_pair[:, 1]], labels_pair[:],validation_split=0.1,batch_size=4,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image_pairs(images_dataset, labels_dataset, image):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label, [index for index, curr_label in enumerate(labels_dataset) if label == curr_label])\n",
    "  \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for label, indices_for_label in label_wise_indices.items():\n",
    "        test_image = images_dataset[np.random.choice(indices_for_label)]\n",
    "        pair_images.append((image, test_image))\n",
    "        pair_labels.append(label)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "  test_image_pairs, test_label_pairs = generate_test_image_pairs(images_dataset, labels_dataset, image) # produce an array of test image pairs and test label pairs\n",
    "  #print(\"Test pairs\", test_image_pairs)\n",
    "  print(\"Test labels\", test_label_pairs)\n",
    "  for index, pair in enumerate(test_image_pairs):\n",
    "      pair_image1 = np.expand_dims(pair[0], axis=-1)\n",
    "      pair_image1 = np.expand_dims(pair_image1, axis=0)\n",
    "      pair_image2 = np.expand_dims(pair[1], axis=-1)\n",
    "      pair_image2 = np.expand_dims(pair_image2, axis=0)\n",
    "      print(model.predict([pair_image1, pair_image2]))\n",
    "      prediction = model.predict([pair_image1, pair_image2])[0][0]\n",
    "      print(\"Test image pair {} similarity: {:.2f}\".format(index, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['david', 'other']\n",
      "Test labels ['david' 'will-smith']\n",
      "1/1 [==============================] - 1s 999ms/step\n",
      "[[0.48815435]]\n",
      "1/1 [==============================] - 1s 634ms/step\n",
      "Test image pair 0 similarity: 0.49\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "[[0.28241676]]\n",
      "1/1 [==============================] - 1s 578ms/step\n",
      "Test image pair 1 similarity: 0.28\n",
      "Test labels ['david' 'will-smith']\n",
      "1/1 [==============================] - 1s 642ms/step\n",
      "[[0.37741807]]\n",
      "1/1 [==============================] - 1s 509ms/step\n",
      "Test image pair 0 similarity: 0.38\n",
      "1/1 [==============================] - 1s 607ms/step\n",
      "[[0.36321118]]\n",
      "1/1 [==============================] - 1s 508ms/step\n",
      "Test image pair 1 similarity: 0.36\n"
     ]
    }
   ],
   "source": [
    "print(labels_test_dataset)\n",
    "\n",
    "# show the first image\n",
    "predict(images_test_dataset[0])\n",
    "\n",
    "predict(images_test_dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
