{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224\n",
    "\n",
    "def create_model():\n",
    "    inputs = Input((img_rows, img_cols, 3))\n",
    "    x = Conv2D(96, (11, 11), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    pooledOutput = Dense(1024)(pooledOutput)\n",
    "    outputs = Dense(128)(pooledOutput)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "feature_extractor = create_model()\n",
    "imgA = Input(shape=(img_rows, img_cols, 3))\n",
    "imgB = Input(shape=(img_rows, img_cols, 3))\n",
    "featA = feature_extractor(imgA)\n",
    "featB = feature_extractor(imgB)\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    (featA, featB) = vectors\n",
    "    sum_squared = K.sum(K.square(featA - featB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "distance = Lambda(euclidean_distance)([featA, featB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_train_image_pairs(images_dataset, labels_dataset):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label,\n",
    "                                      [index for index, curr_label in enumerate(labels_dataset) if\n",
    "                                       label == curr_label])\n",
    "    \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for index, image in enumerate(images_dataset):\n",
    "        pos_indices = label_wise_indices.get(labels_dataset[index])\n",
    "        pos_image = images_dataset[np.random.choice(pos_indices)]\n",
    "        pair_images.append((image, pos_image))\n",
    "        pair_labels.append(1)\n",
    "\n",
    "        neg_indices = np.where(labels_dataset != labels_dataset[index])\n",
    "        neg_image = images_dataset[np.random.choice(neg_indices[0])]\n",
    "        pair_images.append((image, neg_image))\n",
    "        pair_labels.append(0)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 3024, 3) david/test_david10.jpg\n",
      "(600, 434, 3) david/test_will_smith.jpg\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "# pull images from david/ folder\n",
    "images_dataset = []\n",
    "labels_dataset = []\n",
    "images_test_dataset = []\n",
    "labels_test_dataset = []\n",
    "\n",
    "for image_path in glob.glob(\"david/david*.jpg\"):\n",
    "    image = cv2.imread(image_path)\n",
    "    #print(image.shape)\n",
    "    # need to bounding box here\n",
    "    image = cv2.resize(image, (img_rows, img_cols))\n",
    "    image = img_to_array(image)\n",
    "    images_dataset.append(image)\n",
    "    label = \"david\"\n",
    "    labels_dataset.append(label)\n",
    "\n",
    "for image_path in glob.glob(\"david/test*.jpg\"):\n",
    "    image = cv2.imread(image_path)\n",
    "    print(image.shape, image_path)\n",
    "    # need to bounding box here\n",
    "    image = cv2.resize(image, (img_rows, img_cols))\n",
    "    image = img_to_array(image)\n",
    "    images_test_dataset.append(image)\n",
    "    label = \"david\" if \"test_david\" in image_path else \"other\"\n",
    "    labels_test_dataset.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 31s 31s/step - loss: 8.7209 - accuracy: 0.5000 - val_loss: 2.1301 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 23s 23s/step - loss: 4.4903 - accuracy: 0.5000 - val_loss: 0.7949 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 27s 27s/step - loss: 1.4551 - accuracy: 0.5000 - val_loss: 0.6444 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.7440 - accuracy: 0.5000 - val_loss: 0.6467 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 24s 24s/step - loss: 0.6922 - accuracy: 0.5000 - val_loss: 0.6522 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "## Model training\n",
    "\n",
    "images_pair, labels_pair = generate_train_image_pairs(images_dataset, labels_dataset)\n",
    "history = model.fit([images_pair[:, 0], images_pair[:, 1]], labels_pair[:],validation_split=0.1,batch_size=64,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image_pairs(images_dataset, labels_dataset, image):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label, [index for index, curr_label in enumerate(labels_dataset) if label == curr_label])\n",
    "  \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for label, indices_for_label in label_wise_indices.items():\n",
    "        test_image = images_dataset[np.random.choice(indices_for_label)]\n",
    "        pair_images.append((image, test_image))\n",
    "        pair_labels.append(label)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "  test_image_pairs, test_label_pairs = generate_test_image_pairs(images_dataset, labels_dataset, image) # produce an array of test image pairs and test label pairs\n",
    "  #print(\"Test pairs\", test_image_pairs)\n",
    "  print(\"Test labels\", test_label_pairs)\n",
    "  for index, pair in enumerate(test_image_pairs):\n",
    "      pair_image1 = np.expand_dims(pair[0], axis=-1)\n",
    "      pair_image1 = np.expand_dims(pair_image1, axis=0)\n",
    "      pair_image2 = np.expand_dims(pair[1], axis=-1)\n",
    "      pair_image2 = np.expand_dims(pair_image2, axis=0)\n",
    "      prediction = model.predict([pair_image1, pair_image2])[0][0]\n",
    "      print(\"Test image pair {} similarity: {:.2f}\".format(index, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['david', 'other']\n",
      "Test labels ['david']\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Test image pair 0 similarity: 0.51\n",
      "Test labels ['david']\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "Test image pair 0 similarity: 0.53\n"
     ]
    }
   ],
   "source": [
    "print(labels_test_dataset)\n",
    "\n",
    "# show the first image\n",
    "predict(images_test_dataset[0])\n",
    "\n",
    "predict(images_test_dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
