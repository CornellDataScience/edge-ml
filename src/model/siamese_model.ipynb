{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:44:42.168882: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import glob\n",
    "import cv2\n",
    "from tensorflow.keras.utils import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 228, 3) ../../utils/cropped/2023-11-05-17-31-29/test_will_smith.jpg_2.jpg\n"
     ]
    }
   ],
   "source": [
    "# pull images from david/ folder\n",
    "images_dataset = []\n",
    "labels_dataset = []\n",
    "images_test_dataset = []\n",
    "labels_test_dataset = []\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "for image_path in glob.glob(\"../../utils/cropped/2023-11-05-17-29-38/*.jpg\"):\n",
    "    image = cv2.imread(image_path)\n",
    "    #print(image.shape)\n",
    "    # need to bounding box here\n",
    "    image = cv2.resize(image, (img_rows, img_cols))\n",
    "    image = img_to_array(image)\n",
    "    images_dataset.append(image)\n",
    "    label = image_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "    labels_dataset.append(label)\n",
    "\n",
    "for image_path in glob.glob(\"../../utils/cropped/2023-11-05-17-31-29/*.jpg\"):\n",
    "    image = cv2.imread(image_path)\n",
    "    print(image.shape, image_path)\n",
    "    # need to bounding box here\n",
    "    image = cv2.resize(image, (img_rows, img_cols))\n",
    "    image = img_to_array(image)\n",
    "    images_test_dataset.append(image)\n",
    "    label = \"david\" if \"test_david\" in image_path else \"other\"\n",
    "    labels_test_dataset.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in images_dataset, apply bounding box\n",
    "for image in images_dataset:\n",
    "    pass\n",
    "    # apply bounding box\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input((img_rows, img_cols, 3))\n",
    "    x = Conv2D(96, (11, 11), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    pooledOutput = Dense(1024)(pooledOutput)\n",
    "    outputs = Dense(128)(pooledOutput)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "feature_extractor = create_model()\n",
    "imgA = Input(shape=(img_rows, img_cols, 3))\n",
    "imgB = Input(shape=(img_rows, img_cols, 3))\n",
    "featA = feature_extractor(imgA)\n",
    "featB = feature_extractor(imgB)\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    (featA, featB) = vectors\n",
    "    sum_squared = K.sum(K.square(featA - featB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "distance = Lambda(euclidean_distance)([featA, featB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_train_image_pairs(images_dataset, labels_dataset):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    print \n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label,\n",
    "                                      [index for index, curr_label in enumerate(labels_dataset) if\n",
    "                                       label == curr_label])\n",
    "    \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for index, image in enumerate(images_dataset):\n",
    "        pos_indices = label_wise_indices.get(labels_dataset[index])\n",
    "        pos_image = images_dataset[np.random.choice(pos_indices)]\n",
    "        pair_images.append((image, pos_image))\n",
    "        pair_labels.append(1)\n",
    "\n",
    "        neg_indices = np.where(labels_dataset != labels_dataset[index])\n",
    "        neg_image = images_dataset[np.random.choice(neg_indices[0])]\n",
    "        pair_images.append((image, neg_image))\n",
    "        pair_labels.append(0)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 5s 632ms/step - loss: 19.6600 - accuracy: 0.4737 - val_loss: 0.8089 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 4s 742ms/step - loss: 1.7040 - accuracy: 0.4737 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 2s 477ms/step - loss: 0.7672 - accuracy: 0.4737 - val_loss: 0.6497 - val_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 2s 422ms/step - loss: 0.7200 - accuracy: 0.4737 - val_loss: 0.6285 - val_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 2s 388ms/step - loss: 0.7294 - accuracy: 0.4737 - val_loss: 0.6691 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "## Model training\n",
    "\n",
    "images_pair, labels_pair = generate_train_image_pairs(images_dataset, labels_dataset)\n",
    "history = model.fit([images_pair[:, 0], images_pair[:, 1]], labels_pair[:],validation_split=0.1,batch_size=4,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image_pairs(images_dataset, labels_dataset, image):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label, [index for index, curr_label in enumerate(labels_dataset) if label == curr_label])\n",
    "  \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for label, indices_for_label in label_wise_indices.items():\n",
    "        test_image = images_dataset[np.random.choice(indices_for_label)]\n",
    "        pair_images.append((image, test_image))\n",
    "        pair_labels.append(label)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "  test_image_pairs, test_label_pairs = generate_test_image_pairs(images_dataset, labels_dataset, image) # produce an array of test image pairs and test label pairs\n",
    "  #print(\"Test pairs\", test_image_pairs)\n",
    "  print(\"Test labels\", test_label_pairs)\n",
    "  for index, pair in enumerate(test_image_pairs):\n",
    "      pair_image1 = np.expand_dims(pair[0], axis=-1)\n",
    "      pair_image1 = np.expand_dims(pair_image1, axis=0)\n",
    "      pair_image2 = np.expand_dims(pair[1], axis=-1)\n",
    "      pair_image2 = np.expand_dims(pair_image2, axis=0)\n",
    "      print(model.predict([pair_image1, pair_image2]))\n",
    "      prediction = model.predict([pair_image1, pair_image2])[0][0]\n",
    "      print(\"Test image pair {} similarity: {:.2f}\".format(index, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other']\n",
      "Test labels ['david' 'will-smith']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 272ms/step\n",
      "[[0.46272734]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Test image pair 0 similarity: 0.46\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[0.48013836]]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Test image pair 1 similarity: 0.48\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/emily/Desktop/CDS Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# show the first image\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m predict(images_test_dataset[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/emily/Desktop/CDS%20Work/edge-ml-pm/edge-ml/src/model/siamese_model.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predict(images_test_dataset[\u001b[39m1\u001b[39;49m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(labels_test_dataset)\n",
    "\n",
    "# show the first image\n",
    "predict(images_test_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
